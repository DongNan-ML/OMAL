{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0355f92-7104-4030-8e8c-2aebd9837375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import vote_entropy_sampling, max_std_sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from skorch.regressor import NeuralNetRegressor\n",
    "from copy import deepcopy\n",
    "from skorch.dataset import ValidSplit\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.cluster import DBSCAN, OPTICS, cluster_optics_dbscan, Birch, SpectralClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid, ReLU\n",
    "from torch.nn import Module\n",
    "from sklearn.metrics import r2_score\n",
    "import copy\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch import tensor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from model import MLP\n",
    "from model_state import get_model_params, get_input_for_hidden_layers, get_model_params_gradientNorm\n",
    "from functions_batch1 import get_variance, qbc, normalization, error_reduct_fuc, total_disagrement, grad_norm, averaged_grad_norm, get_avg_grad_norm, training_loss\n",
    "import random\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Freezer, Unfreezer\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "from skorch.regressor import NeuralNetRegressor, NeuralNet\n",
    "from model_state import features_concat, learning_state_features_concat\n",
    "import gc\n",
    "import warnings\n",
    "from modAL.utils.selection import multi_argmax\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dceaa95-f840-4923-9958-b246f5d1e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params:\n",
    "query_number = 25          # The number of the AL Iterations in each Exp\n",
    "iteration = 20             # Total number of the Exps\n",
    "batch_size = 10\n",
    "total_initail_size = 9\n",
    "initial_size = 5\n",
    "dimensions = 15   # Total dimension of the data features + model states\n",
    "\n",
    "seed_rf = np.load(file=\"..\\..\\seed2.npy\")\n",
    "seed_initial = np.load(file=\"..\\..\\seed3.npy\")\n",
    "\n",
    "seed_nn1 = np.load(file=\"..\\..\\seed4.npy\")\n",
    "seed_nn2 = np.load(file=\"..\\..\\seed4.npy\")\n",
    "seed_nn3 = np.load(file=\"..\\..\\seed5.npy\")\n",
    "seed_nn4 = np.load(file=\"..\\..\\seed5.npy\")\n",
    "seed_nn5 = np.load(file=\"..\\..\\seed6.npy\")\n",
    "seed_nn6 = np.load(file=\"..\\..\\seed6.npy\")\n",
    "\n",
    "seed_predictor = np.load(file=\"..\\..\\seed7.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3664799-9b42-448e-94de-f424b15c7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Committee_Prediction(learner_list, X_test, y_test):\n",
    "    initial_pred=[]\n",
    "    for i in learner_list:\n",
    "        initial_pred.append(r2_score(y_test, i.predict(X_test)))\n",
    "    initial_pred=np.array(initial_pred)\n",
    "    \n",
    "    return initial_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0488cd6c-903f-4969-88eb-404a307cfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(query_number, iters):\n",
    "    # For saving results:\n",
    "    rf_model_training_r2 = []\n",
    "    rf_model_training_mse = []\n",
    "    rf_model_testing_r2 = []\n",
    "    rf_model_testing_mse = []\n",
    "    \n",
    "    # Number of member in committee:\n",
    "    n_members = 3\n",
    "    learner_list = []\n",
    "    \n",
    "    # The model for evaluation:\n",
    "    rf_model = RandomForestRegressor(random_state=seed_rf[iters], n_estimators=100)\n",
    "    gradient_norms = np.empty(shape=(0, 0))\n",
    "    \n",
    "    # Load the data:\n",
    "    name1 = \"..\\..\\Datasets\\AutoMPG\\X_train\" + str(iters) + \".npy\"\n",
    "    name2 = \"..\\..\\Datasets\\AutoMPG\\X_test\" + str(iters) + \".npy\"\n",
    "    name3 = \"..\\..\\Datasets\\AutoMPG\\y_train\" + str(iters) + \".npy\"\n",
    "    name4 = \"..\\..\\Datasets\\AutoMPG\\y_test\" + str(iters) + \".npy\"\n",
    "    \n",
    "    X_train = np.load(name1, allow_pickle=True).astype(np.float32)\n",
    "    X_test = np.load(name2, allow_pickle=True).astype(np.float32)\n",
    "    y_train = np.load(name3, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    y_test = np.load(name4, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Dimensionality of data:\n",
    "    X = X_train.shape[1]\n",
    "    # The index of the unlabeled pool:\n",
    "    X_index = np.arange(X_train.shape[0])\n",
    "\n",
    "    used_data = np.empty(shape=(0, X))\n",
    "    used_label = np.empty(shape=(0)).reshape(-1, 1)\n",
    "\n",
    "    X_initial = np.empty(shape=(0,X))\n",
    "    y_initial = np.empty(shape=(0)).reshape(-1, 1)\n",
    "    \n",
    "    # Initial Stage 1:\n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "\n",
    "    X_initial = X_train[train_idx]\n",
    "    y_initial = y_train[train_idx].reshape(-1, 1)\n",
    "\n",
    "    used_data = np.append(used_data, X_initial, axis=0).astype(np.float32)\n",
    "    used_label = np.append(used_label, y_initial, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "\n",
    "    \n",
    "    used_data = torch.from_numpy(used_data).to(device)\n",
    "    used_label = torch.from_numpy(used_label).to(device)\n",
    "    for member_idx in range(n_members):\n",
    "        if member_idx == 0:\n",
    "            np.random.seed(seed_nn1[iters])\n",
    "            torch.manual_seed(seed_nn2[iters])\n",
    "        if member_idx == 1:\n",
    "            np.random.seed(seed_nn3[iters])\n",
    "            torch.manual_seed(seed_nn4[iters])\n",
    "        if member_idx == 2:\n",
    "            np.random.seed(seed_nn5[iters])\n",
    "            torch.manual_seed(seed_nn6[iters])\n",
    "            \n",
    "        regressor = NeuralNetRegressor(MLP(X),\n",
    "                                   criterion=MSELoss(),\n",
    "                                   optimizer=torch.optim.Adam,\n",
    "                                   verbose=0,\n",
    "                                   max_epochs=30,\n",
    "                                   lr=0.001,\n",
    "                                   # Used for the batch AL\n",
    "                                   callbacks=[EarlyStopping(patience=5), ('lr_scheduler', LRScheduler(policy=ReduceLROnPlateau))],\n",
    "                                   train_split=ValidSplit(cv=5),\n",
    "                                   warm_start=True,\n",
    "                                   device='cuda',\n",
    "                                   batch_size = 200\n",
    "                                   )\n",
    "        regressor.fit(used_data, used_label)\n",
    "        learner_list.append(regressor)\n",
    "    \n",
    "    print(\"NN Test R2 with 5 samples\", Committee_Prediction(learner_list, X_test, y_test))\n",
    "\n",
    "    # Number of LAL features:\n",
    "    learning_state_features = np.empty(shape=(0, dimensions))\n",
    "    loss_reduction_target = np.empty(shape=(0)).reshape(-1, 1)\n",
    "\n",
    "    # other random samples:\n",
    "    rest_initial_X = np.empty(shape=(0, X))\n",
    "    rest_initial_y = np.empty(shape=(0)).reshape(-1, 1)\n",
    "\n",
    "    # LAL Initialization: Stage 2\n",
    "    predictor = RandomForestRegressor(n_estimators=1000, random_state=seed_predictor[iters])\n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=total_initail_size-initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "    \n",
    "    rest_initial_X = np.append(rest_initial_X, X_train[train_idx], axis=0).astype(np.float32)\n",
    "    rest_initial_y = np.append(rest_initial_y, y_train[train_idx], axis=0).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "\n",
    "    for i in range(rest_initial_X.shape[0]):\n",
    "\n",
    "        single_X = rest_initial_X[i],\n",
    "        single_y = rest_initial_y[i].reshape(1, -1)\n",
    "        single_X = single_X[0].reshape(1, -1)\n",
    "        \n",
    "        single_X = torch.from_numpy(single_X).to(device)\n",
    "        single_y = torch.from_numpy(single_y).to(device)\n",
    "\n",
    "        # Model params\n",
    "        model_params = get_model_params_gradientNorm(learner_list)\n",
    "\n",
    "        # updated data\n",
    "        used_data = torch.cat((used_data, single_X), 0)\n",
    "        used_label = torch.cat((used_label, single_y), 0)\n",
    "\n",
    "        # Retrain the model:\n",
    "        for l in learner_list:\n",
    "            l.fit(X=used_data,y=used_label)\n",
    "            \n",
    "        single_X = single_X.cpu().numpy()\n",
    "        single_y = single_y.cpu().numpy()\n",
    "            \n",
    "        index = train_idx[i]\n",
    "\n",
    "        # The training sample:\n",
    "        data_params = X_train[index]\n",
    "      \n",
    "        LALfeatures = features_concat(model_params, data_params)\n",
    "\n",
    "        loss_reduction = get_avg_grad_norm(learner_list, single_X, single_y)\n",
    "        \n",
    "        learning_state_features = learning_state_features_concat(learning_state_features, LALfeatures)\n",
    "        loss_reduction_target = np.append(loss_reduction_target, np.array([loss_reduction]).reshape(-1, 1), axis=0).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "        \n",
    "    used_data = used_data.cpu().numpy()\n",
    "    used_label = used_label.cpu().numpy()\n",
    "\n",
    "    # Finished the Initialization Stages:\n",
    "    # RF Regressor for evaluation:\n",
    "    rf_model.fit(used_data, used_label.ravel())\n",
    "    # Training Scores:\n",
    "    rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "    rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "    rf_model_training_r2.append(rf_training_r2)\n",
    "    rf_model_training_mse.append(rf_training_mse)\n",
    "    \n",
    "    # Test Scores:\n",
    "    rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "    rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "    rf_model_testing_r2.append(rf_model_r2)\n",
    "    rf_model_testing_mse.append(rf_model_mse)\n",
    "    \n",
    "    print(\"After Initialization RF R2:\", rf_model_r2)\n",
    "    print(\"NN Test R2 after Initialization\", Committee_Prediction(learner_list, X_test, y_test))\n",
    "    \n",
    "    # Reuse training data:\n",
    "    learning_state_features, loss_reduction_target = reuse_labeled_data_meta(used_data, used_label, learner_list, learning_state_features, loss_reduction_target)\n",
    "    print(np.unique(used_data, axis=0).shape)\n",
    "    for idx in range(query_number):\n",
    "        np.random.seed(None)\n",
    "        print('Query no. %d' % (idx+1))\n",
    "        print(learning_state_features.shape)\n",
    "\n",
    "        Error_reduction_list, training_score = error_reduct_fuc(X_train, X_index, learner_list, learning_state_features, loss_reduction_target, X_index.shape[0], predictor)\n",
    "    \n",
    "        idx = multi_argmax(np.array(Error_reduction_list), n_instances=batch_size)\n",
    "       \n",
    "        X_train_indices = X_index[idx]\n",
    "        \n",
    "        # Update\n",
    "        X_index = np.delete(X_index, idx, axis=0)\n",
    "\n",
    "        for X_train_index in X_train_indices:\n",
    "\n",
    "            new_X = X_train[X_train_index].reshape(1, -1)\n",
    "            new_y = y_train[X_train_index].reshape(1, -1)\n",
    "            \n",
    "            used_data = np.append(used_data, new_X, axis=0).astype(np.float32)\n",
    "            used_label = np.append(used_label, new_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "            \n",
    "            used_data = torch.from_numpy(used_data).to(device)\n",
    "            used_label = torch.from_numpy(used_label).to(device)\n",
    "\n",
    "            # Model params\n",
    "            model_params = get_model_params_gradientNorm(learner_list)\n",
    "            data_params = X_train[X_train_index]\n",
    "            LALfeatures = features_concat(model_params, data_params)\n",
    "            \n",
    "            for l in learner_list:\n",
    "                l.fit(used_data, used_label)\n",
    "            \n",
    "            used_data = used_data.cpu().numpy()\n",
    "            used_label = used_label.cpu().numpy()\n",
    "\n",
    "            loss_reduction = get_avg_grad_norm(learner_list, new_X, new_y)  \n",
    "            gradient_norms = np.append(gradient_norms, loss_reduction)\n",
    "            \n",
    "            learning_state_features = learning_state_features_concat(learning_state_features, LALfeatures)\n",
    "            loss_reduction_target = np.append(loss_reduction_target, np.array([loss_reduction]).reshape(-1, 1), axis=0).astype(np.float32).reshape(-1, 1)\n",
    "            \n",
    "        # RF Evaluation\n",
    "        rf_model.fit(used_data, used_label.ravel())\n",
    "        \n",
    "        # Training Evaluation:\n",
    "        rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "        rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "        rf_model_training_r2.append(rf_training_r2)\n",
    "        rf_model_training_mse.append(rf_training_mse)\n",
    "        \n",
    "        # Test Evaluation:\n",
    "        rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "        rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "        rf_model_testing_r2.append(rf_model_r2)\n",
    "        rf_model_testing_mse.append(rf_model_mse)\n",
    "\n",
    "        print(np.unique(used_data, axis=0).shape)\n",
    "        print(\"RF R2:\", rf_model_r2)\n",
    "        print(\"Remaining:\", X_index.shape[0])\n",
    "        # Reuse training data:\n",
    "        learning_state_features, loss_reduction_target = reuse_labeled_data_meta(used_data, used_label, learner_list, learning_state_features, loss_reduction_target)\n",
    "\n",
    "        # print('NN R2', Committee_Prediction(learner_list, X_test, y_test))\n",
    "\n",
    "    # RF\n",
    "    rf_model_testing_r2 = np.array(rf_model_testing_r2)\n",
    "    rf_model_testing_mse = np.array(rf_model_testing_mse)\n",
    "    rf_model_training_r2 = np.array(rf_model_training_r2)\n",
    "    rf_model_training_mse = np.array(rf_model_training_mse)\n",
    "    \n",
    "    # Used_data and Unsed_label:\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\used_data\" + str(iters) + \".npy\", arr=used_data)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\used_labels\" + str(iters) + \".npy\", arr=used_label)\n",
    "\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\testing_rf_r2_\" + str(iters) + \".npy\", arr=rf_model_testing_r2)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\testing_rf_mse_\" + str(iters) + \".npy\", arr=rf_model_testing_mse)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\training_rf_r2_\" + str(iters) + \".npy\", arr=rf_model_training_r2)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\OMAL_append1\\Summary\\\\training_rf_mse_\" + str(iters) + \".npy\", arr=rf_model_training_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189d514a-ed65-4608-83dd-a3e45d0aea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reuse_labeled_data_meta(used_data, used_label, learner_list, learning_state_features, loss_reduction_target):\n",
    "    for i in range(used_data.shape[0]):\n",
    "            \n",
    "            new_X = used_data[i].reshape(1, -1)\n",
    "            new_y = used_label[i].reshape(1, -1)\n",
    "            \n",
    "            used_data_ = np.append(used_data, new_X, axis=0).astype(np.float32)\n",
    "            used_label_ = np.append(used_label, new_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "            \n",
    "            used_data_ = torch.from_numpy(used_data_).to(device)\n",
    "            used_label_ = torch.from_numpy(used_label_).to(device)\n",
    "\n",
    "            # Model params\n",
    "            model_params = get_model_params_gradientNorm(learner_list)\n",
    "            data_params = new_X.reshape(-1,)\n",
    "            LALfeatures = features_concat(model_params, data_params)\n",
    "            \n",
    "            for l in learner_list:\n",
    "                l.fit(used_data_, used_label_)\n",
    "\n",
    "            loss_reduction = get_avg_grad_norm(learner_list, new_X, new_y)  \n",
    "            \n",
    "            learning_state_features = learning_state_features_concat(learning_state_features, LALfeatures)\n",
    "            loss_reduction_target = np.append(loss_reduction_target, np.array([loss_reduction]).reshape(-1, 1), axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    return learning_state_features, loss_reduction_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3f10b-dc78-4f89-97cb-8e635c25e5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Iteration is  0\n",
      "NN Test R2 with 5 samples -9.814066804176191\n",
      "After Initialization RF R2: 0.5768620777292812\n",
      "NN Test R2 after Initialization -2.2961727223425394\n",
      "(9, 7)\n",
      "Query no. 1\n",
      "(13, 15)\n",
      "Embeddings training score: 0.8039105290344004\n",
      "(19, 7)\n",
      "RF R2: 0.5848532679135245\n",
      "Remaining: 294\n",
      "Query no. 2\n",
      "(42, 15)\n",
      "Embeddings training score: 0.8313099930020506\n",
      "(29, 7)\n",
      "RF R2: 0.6000000927713374\n",
      "Remaining: 284\n",
      "Query no. 3\n",
      "(81, 15)\n",
      "Embeddings training score: 0.879323848522892\n",
      "(39, 7)\n",
      "RF R2: 0.6622448205408972\n",
      "Remaining: 274\n",
      "Query no. 4\n",
      "(130, 15)\n",
      "Embeddings training score: 0.913956585774481\n",
      "(49, 7)\n",
      "RF R2: 0.594995328691341\n",
      "Remaining: 264\n",
      "Query no. 5\n",
      "(189, 15)\n",
      "Embeddings training score: 0.9308179583487722\n",
      "(59, 7)\n",
      "RF R2: 0.6190104288779654\n",
      "Remaining: 254\n",
      "Query no. 6\n",
      "(258, 15)\n",
      "Embeddings training score: 0.9259245339602523\n",
      "(69, 7)\n",
      "RF R2: 0.6346893859289535\n",
      "Remaining: 244\n",
      "Query no. 7\n",
      "(337, 15)\n",
      "Embeddings training score: 0.9068055298539238\n",
      "(79, 7)\n",
      "RF R2: 0.6768589679496483\n",
      "Remaining: 234\n",
      "Query no. 8\n",
      "(426, 15)\n",
      "Embeddings training score: 0.9037361694687511\n",
      "(89, 7)\n",
      "RF R2: 0.6728769644280359\n",
      "Remaining: 224\n",
      "Query no. 9\n",
      "(525, 15)\n",
      "Embeddings training score: 0.8929005338128384\n",
      "(99, 7)\n",
      "RF R2: 0.6383208687557876\n",
      "Remaining: 214\n",
      "Query no. 10\n",
      "(634, 15)\n",
      "Embeddings training score: 0.8979704632442106\n",
      "(109, 7)\n",
      "RF R2: 0.7565794980769588\n",
      "Remaining: 204\n",
      "Query no. 11\n",
      "(753, 15)\n",
      "Embeddings training score: 0.9010005523189366\n",
      "(119, 7)\n",
      "RF R2: 0.7591997152426323\n",
      "Remaining: 194\n",
      "Query no. 12\n",
      "(882, 15)\n",
      "Embeddings training score: 0.9091579705367215\n",
      "(129, 7)\n",
      "RF R2: 0.7778384400196265\n",
      "Remaining: 184\n",
      "Query no. 13\n",
      "(1021, 15)\n",
      "Embeddings training score: 0.8673286926394556\n",
      "(139, 7)\n",
      "RF R2: 0.7658135411607236\n",
      "Remaining: 174\n",
      "Query no. 14\n",
      "(1170, 15)\n",
      "Embeddings training score: 0.8875099033076269\n",
      "(149, 7)\n",
      "RF R2: 0.7705454310343007\n",
      "Remaining: 164\n",
      "Query no. 15\n",
      "(1329, 15)\n",
      "Embeddings training score: 0.8895873528203807\n",
      "(159, 7)\n",
      "RF R2: 0.76807359487675\n",
      "Remaining: 154\n",
      "Query no. 16\n",
      "(1498, 15)\n",
      "Embeddings training score: 0.890763633004937\n",
      "(169, 7)\n",
      "RF R2: 0.7687616245790697\n",
      "Remaining: 144\n",
      "Query no. 17\n",
      "(1677, 15)\n",
      "Embeddings training score: 0.8915045748028426\n",
      "(179, 7)\n",
      "RF R2: 0.7752139334954693\n",
      "Remaining: 134\n",
      "Query no. 18\n",
      "(1866, 15)\n",
      "Embeddings training score: 0.8924932229209522\n",
      "(189, 7)\n",
      "RF R2: 0.7828736099692866\n",
      "Remaining: 124\n",
      "Query no. 19\n",
      "(2065, 15)\n",
      "Embeddings training score: 0.8878388444583332\n",
      "(199, 7)\n",
      "RF R2: 0.7820088301988397\n",
      "Remaining: 114\n",
      "Query no. 20\n",
      "(2274, 15)\n",
      "Embeddings training score: 0.8890639158045921\n",
      "(209, 7)\n",
      "RF R2: 0.7869395191836858\n",
      "Remaining: 104\n",
      "Query no. 21\n",
      "(2493, 15)\n",
      "Embeddings training score: 0.886961610097322\n",
      "(219, 7)\n",
      "RF R2: 0.7932239708026539\n",
      "Remaining: 94\n",
      "Query no. 22\n",
      "(2722, 15)\n",
      "Embeddings training score: 0.8884102379604152\n",
      "(229, 7)\n",
      "RF R2: 0.7932175551058102\n",
      "Remaining: 84\n",
      "Query no. 23\n",
      "(2961, 15)\n",
      "Embeddings training score: 0.8926032022219382\n",
      "(239, 7)\n",
      "RF R2: 0.8011756862441661\n",
      "Remaining: 74\n",
      "Query no. 24\n",
      "(3210, 15)\n",
      "Embeddings training score: 0.8973968304672321\n",
      "(249, 7)\n",
      "RF R2: 0.8033680587970283\n",
      "Remaining: 64\n",
      "Query no. 25\n",
      "(3469, 15)\n",
      "Embeddings training score: 0.9027213337088609\n",
      "(259, 7)\n",
      "RF R2: 0.8090079644974248\n",
      "Remaining: 54\n",
      "The Iteration is  1\n",
      "NN Test R2 with 5 samples -7.294273204866028\n",
      "After Initialization RF R2: 0.4894693495828669\n",
      "NN Test R2 after Initialization -1.8822547669666723\n",
      "(9, 7)\n",
      "Query no. 1\n",
      "(13, 15)\n",
      "Embeddings training score: 0.9185133189043176\n",
      "(19, 7)\n",
      "RF R2: 0.6925640120590011\n",
      "Remaining: 294\n",
      "Query no. 2\n",
      "(42, 15)\n",
      "Embeddings training score: 0.8508883509954523\n",
      "(29, 7)\n",
      "RF R2: 0.7250965208824047\n",
      "Remaining: 284\n",
      "Query no. 3\n",
      "(81, 15)\n",
      "Embeddings training score: 0.860593935173591\n",
      "(39, 7)\n",
      "RF R2: 0.7913128193135951\n",
      "Remaining: 274\n",
      "Query no. 4\n",
      "(130, 15)\n",
      "Embeddings training score: 0.8807121738335851\n",
      "(49, 7)\n",
      "RF R2: 0.8011964404321421\n",
      "Remaining: 264\n",
      "Query no. 5\n",
      "(189, 15)\n",
      "Embeddings training score: 0.880196498421703\n",
      "(59, 7)\n",
      "RF R2: 0.8327180552961562\n",
      "Remaining: 254\n",
      "Query no. 6\n",
      "(258, 15)\n",
      "Embeddings training score: 0.895431513616412\n",
      "(69, 7)\n",
      "RF R2: 0.8510676583352562\n",
      "Remaining: 244\n",
      "Query no. 7\n",
      "(337, 15)\n",
      "Embeddings training score: 0.9072380605602501\n",
      "(79, 7)\n",
      "RF R2: 0.8225101497606994\n",
      "Remaining: 234\n",
      "Query no. 8\n",
      "(426, 15)\n",
      "Embeddings training score: 0.9161305926853183\n",
      "(89, 7)\n",
      "RF R2: 0.8442059338706833\n",
      "Remaining: 224\n",
      "Query no. 9\n",
      "(525, 15)\n",
      "Embeddings training score: 0.9293846631201049\n",
      "(99, 7)\n",
      "RF R2: 0.8306229784597786\n",
      "Remaining: 214\n",
      "Query no. 10\n",
      "(634, 15)\n",
      "Embeddings training score: 0.9289417671618156\n",
      "(109, 7)\n",
      "RF R2: 0.8276636128445456\n",
      "Remaining: 204\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    print(\"The Iteration is \", i)\n",
    "    main_function(query_number, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
