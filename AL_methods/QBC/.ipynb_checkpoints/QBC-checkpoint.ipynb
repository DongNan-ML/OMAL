{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c42376-048d-4059-ba5b-290fb150b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import vote_entropy_sampling, max_std_sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from skorch.regressor import NeuralNetRegressor\n",
    "from copy import deepcopy\n",
    "from skorch.dataset import ValidSplit\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.cluster import DBSCAN, OPTICS, cluster_optics_dbscan, Birch, SpectralClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid, ReLU\n",
    "from torch.nn import Module\n",
    "from sklearn.metrics import r2_score\n",
    "import copy\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch import tensor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from model import MLP\n",
    "import random\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Freezer, Unfreezer\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "from skorch.regressor import NeuralNetRegressor, NeuralNet\n",
    "from modAL.utils.selection import multi_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fa2b55-3ddf-42b5-af18-2204ca288d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params:\n",
    "query_number = 20          # The number of the AL Iterations in each Exp\n",
    "iteration = 20             # Total number of the Exps\n",
    "batch_size = 10\n",
    "total_initail_size = 10\n",
    "initial_size = 5\n",
    "n_members = 3\n",
    "    \n",
    "seed_rf = np.load(file=\"..\\..\\Datasets\\Diabetes\\seed_for_RF.npy\")\n",
    "seed_initial = np.load(file=\"..\\..\\Datasets\\Diabetes\\seed_for_initialSamples.npy\")\n",
    "\n",
    "seed_nn1 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn1.npy\")\n",
    "seed_nn2 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn2.npy\")\n",
    "seed_nn3 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn3.npy\")\n",
    "seed_nn4 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn4.npy\")\n",
    "seed_nn5 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn5.npy\")\n",
    "seed_nn6 = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_for_nn6.npy\")\n",
    "\n",
    "seed_predictor = np.load(file=\"..\\..\\Results\\Res_Diabetes\\OMAL\\seed_predictor.npy\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4b4d3e-a21a-47b0-a67e-620b60531efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Committee_Prediction(learner_list, X_test, y_test):\n",
    "    initial_pred=[]\n",
    "    for i in learner_list:\n",
    "        initial_pred.append(r2_score(y_test, i.predict(X_test)))\n",
    "    initial_pred=np.array(initial_pred)\n",
    "    \n",
    "    return initial_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc25fb66-b970-4f6d-841b-611b12c8344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_QBC(unlebeled_samples, learner_list, n_instances=batch_size):\n",
    "    initial_pred=np.empty(shape=(n_members, unlebeled_samples.shape[0]))\n",
    "    for i in range(n_members):\n",
    "        initial_pred[i,:] = learner_list[i].predict(unlebeled_samples).reshape(1, -1)\n",
    "    std = np.std(initial_pred, axis=0)\n",
    "    return multi_argmax(std, n_instances=n_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfde7e20-f699-46f3-bc85-c16e5f498323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(query_number, iters):\n",
    "# For saving results:\n",
    "    rf_model_training_r2 = []\n",
    "    rf_model_training_mse = []\n",
    "    rf_model_testing_r2 = []\n",
    "    rf_model_testing_mse = []\n",
    "    \n",
    "    # Number of member in committee:\n",
    "    learner_list = []\n",
    "    \n",
    "    # The model for evaluation:\n",
    "    rf_model = RandomForestRegressor(random_state=seed_rf[iters], n_estimators=100)\n",
    "    \n",
    "    # Load the data:\n",
    "    name1 = \"..\\..\\Datasets\\Diabetes\\X_train\" + str(iters) + \".npy\"\n",
    "    name2 = \"..\\..\\Datasets\\Diabetes\\X_test\" + str(iters) + \".npy\"\n",
    "    name3 = \"..\\..\\Datasets\\Diabetes\\y_train\" + str(iters) + \".npy\"\n",
    "    name4 = \"..\\..\\Datasets\\Diabetes\\y_test\" + str(iters) + \".npy\"\n",
    "    \n",
    "    X_train = np.load(name1, allow_pickle=True).astype(np.float32)\n",
    "    X_test = np.load(name2, allow_pickle=True).astype(np.float32)\n",
    "    y_train = np.load(name3, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    y_test = np.load(name4, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Feature Dim\n",
    "    X = X_train.shape[1]\n",
    "    # The unlabeled pool\n",
    "    X_index = np.arange(X_train.shape[0])\n",
    "    \n",
    "    # Queried samples and labels\n",
    "    used_data = np.empty(shape=(0, X))\n",
    "    used_label = np.empty(shape=(0)).reshape(-1, 1)\n",
    "    \n",
    "    # Initial samples and labels\n",
    "    X_initial = np.empty(shape=(0,X))\n",
    "    y_initial = np.empty(shape=(0)).reshape(-1, 1)\n",
    "\n",
    "    # Initial Stage 1:\n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "\n",
    "    X_initial = X_train[train_idx]\n",
    "    y_initial = y_train[train_idx].reshape(-1, 1)\n",
    "\n",
    "    used_data = np.append(used_data, X_initial, axis=0).astype(np.float32)\n",
    "    used_label = np.append(used_label, y_initial, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "    \n",
    "    # Initial Sagte 2:\n",
    "    rest_initial_X = np.empty(shape=(0,X))\n",
    "    rest_initial_y = np.empty(shape=(0)).reshape(-1, 1)\n",
    "    \n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=total_initail_size-initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "    \n",
    "    rest_initial_X = np.append(rest_initial_X, X_train[train_idx], axis=0).astype(np.float32)\n",
    "    rest_initial_y = np.append(rest_initial_y, y_train[train_idx], axis=0).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "    \n",
    "    used_data = np.append(used_data, rest_initial_X, axis=0).astype(np.float32)\n",
    "    used_label = np.append(used_label, rest_initial_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Finished the Initialization Stages:\n",
    "    # RF Regressor for evaluation:\n",
    "    rf_model.fit(used_data, used_label.ravel())\n",
    "    # Training Scores:\n",
    "    rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "    rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "    rf_model_training_r2.append(rf_training_r2)\n",
    "    rf_model_training_mse.append(rf_training_mse)\n",
    "    \n",
    "    # Test Scores:\n",
    "    rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "    rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "    rf_model_testing_r2.append(rf_model_r2)\n",
    "    rf_model_testing_mse.append(rf_model_mse)\n",
    "\n",
    "    print(\"After Initialization RF R2:\", rf_model_r2)\n",
    "\n",
    "    used_data = torch.from_numpy(used_data).to(device)\n",
    "    used_label = torch.from_numpy(used_label).to(device)\n",
    "    for member_idx in range(n_members):\n",
    "        \n",
    "        if member_idx == 0:\n",
    "            np.random.seed(seed_nn1[iters])\n",
    "            torch.manual_seed(seed_nn2[iters])\n",
    "        if member_idx == 1:\n",
    "            np.random.seed(seed_nn3[iters])\n",
    "            torch.manual_seed(seed_nn4[iters])\n",
    "        if member_idx == 2:\n",
    "            np.random.seed(seed_nn5[iters])\n",
    "            torch.manual_seed(seed_nn6[iters])\n",
    "            \n",
    "        regressor = NeuralNetRegressor(MLP(X),\n",
    "                                   criterion=MSELoss(),\n",
    "                                   optimizer=torch.optim.Adam,\n",
    "                                   verbose=0,\n",
    "                                   max_epochs=100,\n",
    "                                   lr=0.001,\n",
    "                                   # Used for the batch AL\n",
    "                                   callbacks=[EarlyStopping(patience=20), ('lr_scheduler', LRScheduler(policy=ReduceLROnPlateau))],\n",
    "                                   train_split=ValidSplit(cv=5),\n",
    "                                   warm_start=False,\n",
    "                                   device='cuda',\n",
    "                                   batch_size = -1\n",
    "                                   )\n",
    "        regressor.fit(used_data, used_label)\n",
    "        learner_list.append(regressor)\n",
    "    \n",
    "    print(\"NN Test R2 after Initialization\", Committee_Prediction(learner_list, X_test, y_test))\n",
    "    print('NN R2', Committee_Prediction(learner_list, X_test, y_test))\n",
    "\n",
    "    for idx in range(query_number):\n",
    "        print('Query no. %d' % (idx+1))\n",
    "\n",
    "        idx = query_QBC(X_train[X_index], learner_list, n_instances=batch_size)\n",
    "\n",
    "        # Query the new sample:\n",
    "        X_train_index = X_index[idx]\n",
    "\n",
    "        new_X = X_train[X_train_index].reshape(batch_size, -1)\n",
    "        new_y = y_train[X_train_index].reshape(batch_size, -1)\n",
    "\n",
    "        # Adding the used data to the used_data pool\n",
    "        used_data = used_data.cpu().numpy()\n",
    "        used_label = used_label.cpu().numpy()\n",
    "        used_data = np.append(used_data, new_X, axis=0).astype(np.float32)\n",
    "        used_label = np.append(used_label, new_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "        \n",
    "        # RF Evaluation\n",
    "        rf_model.fit(used_data, used_label.ravel())\n",
    "        \n",
    "        # Training Evaluation:\n",
    "        rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "        rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "        rf_model_training_r2.append(rf_training_r2)\n",
    "        rf_model_training_mse.append(rf_training_mse)\n",
    "        \n",
    "        # Test Evaluation:\n",
    "        rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "        rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "        rf_model_testing_r2.append(rf_model_r2)\n",
    "        rf_model_testing_mse.append(rf_model_mse)\n",
    "\n",
    "        print(np.unique(used_data, axis=0).shape)\n",
    "        print(\"RF R2:\", rf_model_r2)\n",
    "        print(\"Remaining:\", X_index.shape[0])\n",
    "\n",
    "        # remove queried instance from pool\n",
    "        X_index = np.delete(X_index, idx, axis=0)\n",
    "        \n",
    "        used_data = torch.from_numpy(used_data).to(device)\n",
    "        used_label = torch.from_numpy(used_label).to(device)\n",
    "        \n",
    "        # Retrain the committee:\n",
    "        for l in learner_list:\n",
    "            l.fit(used_data, used_label)\n",
    "            \n",
    "        # print('NN R2', Committee_Prediction(learner_list, X_test, y_test))\n",
    "    \n",
    "    rf_model_testing_r2 = np.array(rf_model_testing_r2)\n",
    "    rf_model_testing_mse = np.array(rf_model_testing_mse)\n",
    "    rf_model_training_r2 = np.array(rf_model_training_r2)\n",
    "    rf_model_training_mse = np.array(rf_model_training_mse)\n",
    "    \n",
    "    # Used_data and Unsed_label:\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\used_data\" + str(iters) + \".npy\", arr=used_data)\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\used_labels\" + str(iters) + \".npy\", arr=used_label)\n",
    "\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\testing_rf_r2_\" + str(iters) + \".npy\", arr=rf_model_testing_r2)\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\testing_rf_mse_\" + str(iters) + \".npy\", arr=rf_model_testing_mse)\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\training_rf_r2_\" + str(iters) + \".npy\", arr=rf_model_training_r2)\n",
    "    np.save(file=\"..\\..\\Results\\Res_Diabetes\\QBC\\Summary\\\\training_rf_mse_\" + str(iters) + \".npy\", arr=rf_model_training_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37ea35d-6803-4cfa-8923-500e0465578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Iteration is  0\n",
      "After Initialization RF R2: 0.01017105099476967\n",
      "NN Test R2 after Initialization -3.2036175220539698\n",
      "NN R2 -3.2036175220539698\n",
      "Query no. 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'multi_argmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28492\\3927749472.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The Iteration is \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28492\\1525908599.py\u001b[0m in \u001b[0;36mmain_function\u001b[1;34m(query_number, iters)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Query no. %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_QBC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearner_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_instances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# Query the new sample:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28492\\188626887.py\u001b[0m in \u001b[0;36mquery_QBC\u001b[1;34m(unlebeled_samples, learner_list, n_instances)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0minitial_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlebeled_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmulti_argmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_instances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_argmax' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    print(\"The Iteration is \", i)\n",
    "    main_function(query_number, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
